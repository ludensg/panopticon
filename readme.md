# **Panopticon: A Parent-Curated AI-Assisted Social Media Simulator**  
*A responsible-AI sandbox for teaching digital literacy, online social skills, and safe communication to children.*

---

## **Table of Contents**

1. [Overview](#overview)  
2. [Why Panopticon Exists](#why-why-panopticon-exists)  
3. [Core Concepts](#core-concepts)  
4. [Feature Summary](#feature-summary)  
5. [System Architecture](#system-architecture)  
6. [Data Model](#data-model)  
7. [Feed Generation](#feed-generation)  
8. [Direct Messages (DMs)](#direct-messages-dms)  
9. [Simulation Engine](#simulation-engine)  
10. [Analytics & Evaluation](#analytics--evaluation)  
11. [Safety & Responsible-AI Framework](#safety--responsible-ai-framework)  
12. [Persistence (Planned)](#persistence-planned)  
13. [Installation & Running](#installation--running)  
14. [Future Directions](#future-directions)  

---

# **Overview**

**Panopticon** is a browser-based prototype built in **Python** with **Streamlit**, **OpenAI/Ollama LLMs**, and **lightweight image search APIs**.  
It simulates a safe “social media feed” for children—generated entirely by AI, curated by parents, and structured to teach healthy online behavior.

It is designed as a **graduate-level AI/CS project** exploring:

- AI development lifecycles  
- Level-2 prompting & ReAct prompting  
- Responsible use of generative models  
- Multi-agent simulations  
- Data modeling & UI state management  

---

# **Why Panopticon Exists**

Children today grow up inside algorithmic systems they do not understand:

- Real social networks are addictive by design.  
- Recommendation engines reward extremes.  
- Parental controls focus on blocking, not *teaching*.  
- Children face risks: oversharing, cyberbullying, deceptive interactions, online pressure, “stranger danger,” etc.

**Panopticon flips the paradigm:**

Instead of placing a child into the real algorithmic world, we **simulate** a curated social environment:

- Safe  
- Transparent  
- Friendly  
- Configurable  
- Pedagogically useful  
- And still *fun*  

It gives parents a new tool: not censorship, but **guided practice**.

---

# **Core Concepts**

### **1. Gardens**  
A **Garden** represents a family environment or scenario.  
Each garden contains:

- Multiple children  
- Feed settings  
- Synthetic friend profiles  
- DM histories  
- Simulation events  

Parents can switch gardens instantly—useful for testing different profiles or training situations.

---

### **2. Children**

Each child has:

- A name & age  
- Interests (topics with weights)  
- Feed behavior settings  
- Their own feed timeline  
- Their own DMs  
- Their own simulation history  

Everything is *per child*, not global.

---

### **3. Modes**

Two distinct tones:

#### **Realistic Mode**  
- Feels like mainstream social media  
- Posts look normal but are child-safe  
- No AI/meta references  
- Informative and engaging  

#### **Gamified Mode**  
- Bright, exaggerated, emoji-heavy  
- Clearly fictional and safe  
- Avoids any risk of confusing simulation with real people  

---

# **Feature Summary**

### ✔ **Parent Dashboard**  
Configure children, interests, number of posts, mode, safety settings, quiet hours, and per-child feed preferences.

### ✔ **Dynamic AI Feed Generation**  
- Posts generated by LLM  
- Tinted avatars  
- Realistic OR cartoon-style personas  
- Kid-friendly “news-like” content available  
- Informative, engaging tone  
- External topic-relevant images shown in feed  

### ✔ **Profile System**  
- Synthetic friends with personality traits  
- Hue-tinted avatars  
- Automatic reuse of profiles for the same topic  
- Circular avatar rendering  

### ✔ **Direct Messages (DMs)**  
- Facebook/Instagram-style DM UI  
- Children can message any profile  
- Parents can read all messages  
- Sim agents can join DM threads  
- Smooth, streaming-free UI (no loading spinner shown)  
- Conversations persist per child  

### ✔ **Simulation Engine**  
This is the most important innovation.

Parents can:

- Manually inject simulation content  
- OR launch **auto-simulations**, where an AI agent:
  1. Generates a synthetic profile  
  2. Initiates a realistic scenario  
  3. Interacts over multiple turns  
  4. Decides **when to end**  
  5. Evaluates the child's responses  
  6. Returns a summary to the parent dashboard  

Sim types include:

- Oversharing risk  
- Bullying pressure  
- Subtle stranger danger  
- Peer-pressure to reveal private info  
- Request for inappropriate photos (handled kid-safely, never graphic)  
- Aggressive/uncomfortable conversation patterns  

**All interactions are age-appropriate and non-traumatic.**

---

### ✔ **Analytics Dashboard**  

Parents can see:

- Simulation summaries  
- Conversation histories  
- Topic distribution in feeds  
- Activity patterns  
- Safety assessments from AI evaluator  

Simulations appear like a **carousel**: click a card to see the scenario summary, then view the full DM transcript.

---

# **System Architecture**

Panopticon is intentionally structured so the UI, domain logic, and AI logic remain separate.

```
panopticon/
│
├── app.py                ← Streamlit UI
│
├── models.py             ← Dataclasses for all objects
│
├── feed_generator.py     ← Topic sampling, LLM calls, post assembly
│
├── simulation_engine.py  ← Multi-turn agents, eval cycles
│
├── llm_client.py         ← OpenAI/Ollama wrapper
│
├── prompts.py            ← All prompt templates
│
├── avatar_utils.py       ← Avatar tinting + circular rendering
│
├── image_search.py       ← Pixabay safe-search wrapper
│
└── assets/               ← Base avatar, icons, etc.
```

Key architectural outcomes:

- Clear modularity  
- Maintainable growth path  
- Easy replacement of AI backends  
- Prompts and UI logic separated cleanly  

---

# **Data Model**

### **GardenState**
Represents an entire family environment:

```python
GardenState:
    id: str
    name: str
    children: List[ChildState]
    profiles: List[Profile]
    posts: List[Post]
    dm_messages: List[DMMessage]
    simulation_events: List[SimulationEvent]
```

---

### **ChildConfig**
Per-child preferences:

- Mode  
- Interests  
- Quiet hours & post limits  
- News-vs-social ratio  
- Image ratio  
- Safety configurations  

---

### **Profile**
Synthetic personas:

- Display name  
- Personality tags  
- Topics  
- Hue shift for avatar  

---

### **Post**
Displayed in the feed:

- Author  
- Text  
- Topic  
- Mode  
- Optional image_url  
- Render-friendly  

---

### **DMMessage**
Represents direct messages in a conversation:

- Sender  
- Receiver  
- Timestamp  
- Simulation flags  
- Text  

---

### **SimulationEvent**
Represents a multi-turn scenario with:

- The agent  
- The child  
- The scenario type  
- Interaction history  
- Outcome label  
- Evaluation summary  

---

# **Feed Generation**

### **Topic Sampling**
Weighted random sampling by child interests.

### **Post Flavoring**
Each post can be:

- “Personal update”  
- “Kid-friendly news”  

Controlled by **news_ratio**.

### **LLM Post Creation**

Each post prompt includes:

- Topic  
- Child age  
- Child’s interests  
- Author persona  
- Desired flavor  
- Safety constraints  

### **Images**
If `image_ratio` is met:

- A safe-search image is retrieved from **Pixabay API**  
- Always small, thumbnail-sized  
- Shown in a dedicated side column  

### **Avatar Tinting**
Using HSV rotation and circular cropping, to generate diverse-looking friend profiles.


## Adaptive Feed & Child Skill Profile

Panopticon’s feed is not just topic-based — it is **adaptive**.  
Each child has a lightweight **skill profile** that evolves over time based on their behavior in simulations, and this profile influences how future posts are generated.

### ChildSkillProfile

For every child, the system tracks a small set of skills on a 0.0–1.0 scale:

- `boundary_setting` – how well the child maintains healthy boundaries.
- `info_sharing_safety` – how cautious they are with personal information.
- `emotional_clarity` – how clearly they express their feelings.
- `peer_pressure_resistance` – how well they handle social pressure.
- `curiosity` – how eager they are to learn and ask questions.

This is stored as a `ChildSkillProfile` attached to each `ChildState`.

### How skills are updated

When a simulation ends, the evaluator LLM produces a textual summary of the child’s behavior.  
A small rule-based layer parses that summary for signals like:

- “overshared”, “shared too much”, “gave personal details” → lowers `info_sharing_safety`.
- “could not say no”, “hesitated to say no”, “went along” → lowers `boundary_setting` and `peer_pressure_resistance`.
- “handled pressure well”, “resisted pressure”, “stood up for themselves” → raises `peer_pressure_resistance` and `boundary_setting`.
- “asked good questions”, “curious”, “wanted to know more” → raises `curiosity`.
- “explained their feelings”, “expressed how they felt” → raises `emotional_clarity`.

After each evaluation, scores are clamped back into the range `[0.0, 1.0]`.

This is intentionally simple and transparent: it can be refined or replaced by a more sophisticated model later, but is already enough to demonstrate adaptive behavior in the prototype.

### Adaptive context in feed prompts

When generating posts for a child, Panopticon builds an **adaptive context** string that describes the current skill profile, for example:

> Boundary-setting: 0.30  
> Information safety: 0.40  
> Peer pressure resistance: 0.25  
> Emotional clarity: 0.60  
> Curiosity: 0.80  

This context is injected into the LLM prompt for each post as `{adaptive_context}`.

The prompt instructs the model to:

- **Model stronger behavior** in skills where the child is weak (e.g., show characters setting boundaries, avoiding oversharing).
- **Reinforce good patterns** where the child is already doing well.
- Stay age-appropriate, non-judgmental, and emotionally supportive.

The child never sees these scores or instructions directly — they only experience a feed that gradually shifts toward content that **teaches and models** the patterns they most need to practice.

### Topic and flavor adaptation

The adaptive profile also influences **what** kinds of posts are generated:

- Lower `boundary_setting` or `peer_pressure_resistance` → the system leans more toward friendship / social posts that quietly demonstrate saying “no”, setting limits, and handling pressure.
- Lower `info_sharing_safety` → more posts model safe sharing and privacy-aware behavior.
- Higher `curiosity` → a larger fraction of posts are “kid-friendly news”, highlighting positive real-world developments and inviting questions.

This turns the child’s feed into a **personalized teaching engine**: every simulation not only gets evaluated, but also nudges how the future feed looks and behaves for that specific child.

---

# **Direct Messages (DMs)**

DM functionality mirrors a lightweight messaging platform:

- Left column: profile list  
- Middle: conversation thread  
- Bottom: message input  
- Right (optional): simulation options  

All messages persist inside the active garden.

The UI intentionally suppresses the Streamlit “loading” animation to keep the messaging interaction feeling natural.

---

# **Simulation Engine**

This is the core of Panopticon.

### **Two modes of initiation**

#### 1. **Manual Simulation**
Parent selects:

- The profile to simulate as  
- A scenario template  
- First injected message  

Useful for targeted teaching.

#### 2. **Auto-Simulation (One-click)**
Parent presses a single button → system:

1. Creates a simulation profile  
2. Starts a multi-turn scenario  
3. Monitors child's replies  
4. Ends the scenario when appropriate  
5. Evaluates behavior  
6. Sends the summary to the parent  

### **Multi-turn Agent Behavior**

The agent:

- Reads full conversation history  
- Produces realistic persona-specific responses  
- Pushes gently toward the scenario goal  
- Ends the simulation when:
  - The child overshares dangerously  
  - The child shows strong resistance  
  - The scenario plates have been exhausted  

### **Evaluation**
After ending, a second LLM:

- Reviews the transcript  
- Rates the child’s performance  
- Labels the scenario outcome  
- Summarizes key risky/safe behaviors  

---

# **Analytics & Evaluation**

Analytics page shows:

- A carousel of simulation results  
- Summaries + timestamps  
- Outcome labels (“safe”, “needs guidance”, etc.)  
- Full DM transcripts  
- Topic distribution in post feeds  
- Activity timestamps  

---

# **Safety & Responsible-AI Framework**

Safety is central. Key design decisions:

### ✔ No deception  
In Gamified mode, everything is explicitly fictional.  
Realistic mode is *kid-safe* and never pretends to be a real person.

### ✔ Age-sensitive prompts  
Prompts are engineered to avoid:

- Sexual content  
- Graphic or traumatic scenarios  
- Violence  
- Excessively negative or frightening news  
- Manipulative patterns (unless simulation requires mild pressure, handled responsibly)

### ✔ No metadata leakage  
Posts never mention AI, the app, or simulation internally.

### ✔ Guardrails on simulations  
Agents avoid harm, avoid graphic material, and follow tight persona boundaries.

### ✔ Parent transparency  
Parents can see:

- Every message  
- Every simulation  
- Every evaluation  

Nothing is hidden.

---

# **Persistence (Planned)**

The next development phase introduces:

- `to_dict()` / `from_dict()` for all dataclasses  
- A `persistence.py` module  
- A JSON or local DB backend  
- “Save / Load / Autosave” buttons in UI  

This will allow:

- Long-term simulation history  
- Teacher/clinician demonstrations  
- User studies  

---

# **Installation & Running**

**Prerequisites**

- Python 3.10+  
- Virtual environment  
- Streamlit  
- OpenAI SDK  
- Ollama (optional, for local LLMs)  
- Pixabay API key (free, for images)

---

## **Setup**

```bash
git clone https://github.com/ludensg/panopticon
cd panopticon

python3 -m venv venv
source venv/bin/activate

pip install -r requirements.txt
```

Set environment variables:

```bash
export OPENAI_API_KEY=your_key_here
export PIXABAY_API_KEY=your_key_here
```

(Optional, if using Ollama)

```bash
ollama pull llama3
```

Run:

```bash
streamlit run app.py
```

---

# **Future Directions**

- Full persistence layer  
- Shared “friend network” across gardens  
- AI-driven parental coaching suggestions  
- Exportable simulation reports  
- Real-time webhooks for research studies  
- Admin dashboard for educators  
- More refined topic ontologies  
- Voice-based scenarios (speech-to-text + TTS)  
- Integration with real news APIs (with curation)  

---

# **Conclusion**

Panopticon demonstrates a **new approach** to online safety and digital literacy:

- Let children practice safely  
- Let parents guide, not forbid  
- Use AI for education rather than surveillance  
- Simulate the real world without exposing them to it  

This README summarizes the system as it stands — a deeply configurable, responsible, pedagogically aligned AI social-media simulator.
